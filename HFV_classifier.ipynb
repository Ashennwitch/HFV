{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FtinFFF5cLJ",
        "outputId": "3b9a352e-2c08-44fe-be60-f2aa7378032f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing PESV v3 Championship (Multi-Model) ---\n",
            "All libraries imported successfully.\n",
            "\n",
            "--- Loading Data for Mode: VPN_ONLY ---\n",
            "Loaded dataset with shape: (2623, 208)\n",
            "Found 128 Alpha'' features.\n",
            "Found 40 Delta features.\n",
            "Found 36 Gamma' features.\n",
            "\n",
            "================================================================================\n",
            "--- STARTING TOURNAMENT FOR TARGET: category ---\n",
            "================================================================================\n",
            "\n",
            "--- Evaluating Contender: Random Forest ---\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.9048 | F1: 0.9036 | Time: 1.38s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Delta (\u03b4) only\n",
            " > Acc: 0.9314 | F1: 0.9310 | Time: 0.98s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.9029 | F1: 0.9028 | Time: 0.96s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Alpha'' + Delta\n",
            " > Acc: 0.9333 | F1: 0.9328 | Time: 0.82s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.9448 | F1: 0.9442 | Time: 0.86s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Delta + Gamma'\n",
            " > Acc: 0.9333 | F1: 0.9336 | Time: 0.69s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.9448 | F1: 0.9451 | Time: 0.97s\n",
            "\n",
            "--- Evaluating Contender: SVM ---\n",
            "\n",
            "Running: SVM | Target: category | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.8419 | F1: 0.8401 | Time: 0.20s\n",
            "\n",
            "Running: SVM | Target: category | Features: Delta (\u03b4) only\n",
            " > Acc: 0.5905 | F1: 0.5963 | Time: 0.29s\n",
            "\n",
            "Running: SVM | Target: category | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.2438 | F1: 0.2627 | Time: 0.39s\n",
            "\n",
            "Running: SVM | Target: category | Features: Alpha'' + Delta\n",
            " > Acc: 0.8324 | F1: 0.8297 | Time: 0.24s\n",
            "\n",
            "Running: SVM | Target: category | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.8362 | F1: 0.8342 | Time: 0.25s\n",
            "\n",
            "Running: SVM | Target: category | Features: Delta + Gamma'\n",
            " > Acc: 0.5600 | F1: 0.5572 | Time: 0.36s\n",
            "\n",
            "Running: SVM | Target: category | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.8324 | F1: 0.8296 | Time: 0.32s\n",
            "\n",
            "--- Evaluating Contender: XGBoost ---\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.8933 | F1: 0.8930 | Time: 3.05s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Delta (\u03b4) only\n",
            " > Acc: 0.9429 | F1: 0.9425 | Time: 2.40s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.8895 | F1: 0.8898 | Time: 1.83s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Alpha'' + Delta\n",
            " > Acc: 0.9505 | F1: 0.9500 | Time: 3.12s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.9371 | F1: 0.9370 | Time: 2.89s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Delta + Gamma'\n",
            " > Acc: 0.9410 | F1: 0.9417 | Time: 1.70s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.9429 | F1: 0.9430 | Time: 5.74s\n",
            "\n",
            "================================================================================\n",
            "--- STARTING TOURNAMENT FOR TARGET: application ---\n",
            "================================================================================\n",
            "\n",
            "--- Evaluating Contender: Random Forest ---\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.8914 | F1: 0.8896 | Time: 0.66s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Delta (\u03b4) only\n",
            " > Acc: 0.9086 | F1: 0.9038 | Time: 0.56s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.8724 | F1: 0.8650 | Time: 0.59s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Alpha'' + Delta\n",
            " > Acc: 0.9029 | F1: 0.8991 | Time: 0.75s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.8971 | F1: 0.8927 | Time: 0.78s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Delta + Gamma'\n",
            " > Acc: 0.9143 | F1: 0.9091 | Time: 0.75s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.9048 | F1: 0.9038 | Time: 0.90s\n",
            "\n",
            "--- Evaluating Contender: SVM ---\n",
            "\n",
            "Running: SVM | Target: application | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.8971 | F1: 0.9009 | Time: 0.14s\n",
            "\n",
            "Running: SVM | Target: application | Features: Delta (\u03b4) only\n",
            " > Acc: 0.7200 | F1: 0.7205 | Time: 0.31s\n",
            "\n",
            "Running: SVM | Target: application | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.2324 | F1: 0.2670 | Time: 0.65s\n",
            "\n",
            "Running: SVM | Target: application | Features: Alpha'' + Delta\n",
            " > Acc: 0.8819 | F1: 0.8851 | Time: 0.19s\n",
            "\n",
            "Running: SVM | Target: application | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.8838 | F1: 0.8889 | Time: 0.17s\n",
            "\n",
            "Running: SVM | Target: application | Features: Delta + Gamma'\n",
            " > Acc: 0.7181 | F1: 0.7188 | Time: 0.39s\n",
            "\n",
            "Running: SVM | Target: application | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.8876 | F1: 0.8917 | Time: 0.22s\n",
            "\n",
            "--- Evaluating Contender: XGBoost ---\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.8800 | F1: 0.8799 | Time: 4.94s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Delta (\u03b4) only\n",
            " > Acc: 0.9143 | F1: 0.9089 | Time: 1.25s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.8838 | F1: 0.8811 | Time: 1.46s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Alpha'' + Delta\n",
            " > Acc: 0.9010 | F1: 0.8978 | Time: 3.33s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.9067 | F1: 0.9037 | Time: 3.24s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Delta + Gamma'\n",
            " > Acc: 0.9295 | F1: 0.9270 | Time: 4.29s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.9086 | F1: 0.9044 | Time: 4.17s\n",
            "\n",
            "================================================================================\n",
            "--- FINAL CHAMPIONSHIP STANDINGS (VPN_ONLY) ---\n",
            "================================================================================\n",
            "\n",
            "--- Target: category ---\n",
            " Model           | Feature Set               | Acc %    | F1 %     | Time (s)\n",
            "-----------------------------------------------------------------------------\n",
            " XGBoost         | Alpha'' + Delta           |  95.05 |  95.00 |   3.12\n",
            " Random Forest   | Alpha'' + Gamma'          |  94.48 |  94.42 |   0.86\n",
            " Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')       |  94.48 |  94.51 |   0.97\n",
            " XGBoost         | Delta (\u03b4) only            |  94.29 |  94.25 |   2.40\n",
            " XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')       |  94.29 |  94.30 |   5.74\n",
            " XGBoost         | Delta + Gamma'            |  94.10 |  94.17 |   1.70\n",
            " XGBoost         | Alpha'' + Gamma'          |  93.71 |  93.70 |   2.89\n",
            " Random Forest   | Alpha'' + Delta           |  93.33 |  93.28 |   0.82\n",
            " Random Forest   | Delta + Gamma'            |  93.33 |  93.36 |   0.69\n",
            " Random Forest   | Delta (\u03b4) only            |  93.14 |  93.10 |   0.98\n",
            " Random Forest   | Alpha'' (\u03b1'') only        |  90.48 |  90.36 |   1.38\n",
            " Random Forest   | Gamma' (\u03b3') only          |  90.29 |  90.28 |   0.96\n",
            " XGBoost         | Alpha'' (\u03b1'') only        |  89.33 |  89.30 |   3.05\n",
            " XGBoost         | Gamma' (\u03b3') only          |  88.95 |  88.98 |   1.83\n",
            " SVM             | Alpha'' (\u03b1'') only        |  84.19 |  84.01 |   0.20\n",
            " SVM             | Alpha'' + Gamma'          |  83.62 |  83.42 |   0.25\n",
            " SVM             | Alpha'' + Delta           |  83.24 |  82.97 |   0.24\n",
            " SVM             | Full (\u03b1'' + \u03b4 + \u03b3')       |  83.24 |  82.96 |   0.32\n",
            " SVM             | Delta (\u03b4) only            |  59.05 |  59.63 |   0.29\n",
            " SVM             | Delta + Gamma'            |  56.00 |  55.72 |   0.36\n",
            " SVM             | Gamma' (\u03b3') only          |  24.38 |  26.27 |   0.39\n",
            "\n",
            "\n",
            "--- Target: application ---\n",
            " Model           | Feature Set               | Acc %    | F1 %     | Time (s)\n",
            "-----------------------------------------------------------------------------\n",
            " XGBoost         | Delta + Gamma'            |  92.95 |  92.70 |   4.29\n",
            " Random Forest   | Delta + Gamma'            |  91.43 |  90.91 |   0.75\n",
            " XGBoost         | Delta (\u03b4) only            |  91.43 |  90.89 |   1.25\n",
            " Random Forest   | Delta (\u03b4) only            |  90.86 |  90.38 |   0.56\n",
            " XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')       |  90.86 |  90.44 |   4.17\n",
            " XGBoost         | Alpha'' + Gamma'          |  90.67 |  90.37 |   3.24\n",
            " Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')       |  90.48 |  90.38 |   0.90\n",
            " Random Forest   | Alpha'' + Delta           |  90.29 |  89.91 |   0.75\n",
            " XGBoost         | Alpha'' + Delta           |  90.10 |  89.78 |   3.33\n",
            " Random Forest   | Alpha'' + Gamma'          |  89.71 |  89.27 |   0.78\n",
            " SVM             | Alpha'' (\u03b1'') only        |  89.71 |  90.09 |   0.14\n",
            " Random Forest   | Alpha'' (\u03b1'') only        |  89.14 |  88.96 |   0.66\n",
            " SVM             | Full (\u03b1'' + \u03b4 + \u03b3')       |  88.76 |  89.17 |   0.22\n",
            " SVM             | Alpha'' + Gamma'          |  88.38 |  88.89 |   0.17\n",
            " XGBoost         | Gamma' (\u03b3') only          |  88.38 |  88.11 |   1.46\n",
            " SVM             | Alpha'' + Delta           |  88.19 |  88.51 |   0.19\n",
            " XGBoost         | Alpha'' (\u03b1'') only        |  88.00 |  87.99 |   4.94\n",
            " Random Forest   | Gamma' (\u03b3') only          |  87.24 |  86.50 |   0.59\n",
            " SVM             | Delta (\u03b4) only            |  72.00 |  72.05 |   0.31\n",
            " SVM             | Delta + Gamma'            |  71.81 |  71.88 |   0.39\n",
            " SVM             | Gamma' (\u03b3') only          |  23.24 |  26.70 |   0.65\n",
            "\n",
            "\n",
            "--- Championship Finished ---\n"
          ]
        }
      ],
      "source": [
        "# --- PESV v3 \"Championship\" Ablation Study (MULTI-MODEL) ---\n",
        "#\n",
        "# This script loads the final 'final_PESV_dataset_v3.csv'\n",
        "# and runs a \"championship\" ablation study comparing:\n",
        "# 1. Random Forest (Bagging)\n",
        "# 2. XGBoost (Boosting)\n",
        "# 3. SVM (Geometric/Hyperplane)\n",
        "#\n",
        "# It iterates through all Tasks -> Models -> Feature Sets automatically.\n",
        "\n",
        "print(\"--- Initializing PESV v3 Championship (Multi-Model) ---\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Try importing XGBoost; handle if missing\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except ImportError:\n",
        "    print(\"WARNING: XGBoost not installed. Skipping XGBoost.\")\n",
        "    HAS_XGB = False\n",
        "\n",
        "print(\"All libraries imported successfully.\")\n",
        "\n",
        "# --- PART 1: Configuration ---\n",
        "\n",
        "# --- !! SET YOUR EXPERIMENT MODE !! ---\n",
        "# \"FULL\"        - Runs on the full v3 dataset\n",
        "# \"VPN_ONLY\"    - Runs on only the VPN samples\n",
        "# \"NONVPN_ONLY\" - Runs on only the NonVPN samples\n",
        "EXPERIMENT_MODE = \"VPN_ONLY\"\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/1 Skripsi/\"\n",
        "FINAL_PESV_FILE = os.path.join(BASE_PATH, \"VPNOnly-final_PESV_dataset_v3.csv\")\n",
        "\n",
        "# --- DEFINE THE CONTENDERS ---\n",
        "MODELS = {\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"SVM\": SVC(\n",
        "        kernel='rbf',\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        probability=False # Set True only if you need predict_proba (slower)\n",
        "    )\n",
        "}\n",
        "\n",
        "# Add XGBoost if installed\n",
        "if HAS_XGB:\n",
        "    MODELS[\"XGBoost\"] = XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        # XGBoost handles multiclass automatically.\n",
        "        # We use default weights here for stability across different tasks.\n",
        "    )\n",
        "\n",
        "TEST_SET_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- PART 2: Load Data and Define Feature Sets ---\n",
        "\n",
        "def load_data(experiment_mode):\n",
        "    \"\"\"Loads and filters the dataset based on the experiment mode.\"\"\"\n",
        "    print(f\"\\n--- Loading Data for Mode: {experiment_mode} ---\")\n",
        "    if not os.path.exists(FINAL_PESV_FILE):\n",
        "        print(f\"FATAL ERROR: Could not find dataset at '{FINAL_PESV_FILE}'\")\n",
        "        return None, None\n",
        "\n",
        "    df_full = pd.read_csv(FINAL_PESV_FILE)\n",
        "\n",
        "    if experiment_mode == \"FULL\":\n",
        "        df = df_full\n",
        "    elif experiment_mode == \"VPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'VPN'].copy()\n",
        "    elif experiment_mode == \"NONVPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'NonVPN'].copy()\n",
        "    else:\n",
        "        print(f\"FATAL ERROR: Unknown experiment mode '{experiment_mode}'\")\n",
        "        return None, None\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"FATAL ERROR: The filtered dataset is empty.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Loaded dataset with shape: {df.shape}\")\n",
        "\n",
        "    # --- Define Feature Column Groups ---\n",
        "    all_cols = set(df.columns)\n",
        "\n",
        "    # 1. Find Alpha'' (\u03b1'') columns\n",
        "    alpha_pp_cols = sorted(list([c for c in all_cols if c.startswith('alpha_pp_')]))\n",
        "\n",
        "    # 2. Find Delta (\u03b4) columns\n",
        "    delta_cols_set = set([c for c in all_cols if\n",
        "                          c.startswith('c2s_') or\n",
        "                          c.startswith('s2c_') or\n",
        "                          c.startswith('flow_') or\n",
        "                          c.startswith('total_')])\n",
        "    delta_cols = sorted(list(delta_cols_set))\n",
        "\n",
        "    # 3. Find Gamma' (\u03b3') columns\n",
        "    gamma_p_cols_set = set([c for c in all_cols if c.startswith('burst_')])\n",
        "    gamma_p_cols = sorted(list(gamma_p_cols_set))\n",
        "\n",
        "    # Master list of feature sets\n",
        "    feature_sets = {\n",
        "        \"Alpha'' (\u03b1'') only\": alpha_pp_cols,\n",
        "        \"Delta (\u03b4) only\": delta_cols,\n",
        "        \"Gamma' (\u03b3') only\": gamma_p_cols,\n",
        "        \"Alpha'' + Delta\": alpha_pp_cols + delta_cols,\n",
        "        \"Alpha'' + Gamma'\": alpha_pp_cols + gamma_p_cols,\n",
        "        \"Delta + Gamma'\": delta_cols + gamma_p_cols,\n",
        "        \"Full (\u03b1'' + \u03b4 + \u03b3')\": alpha_pp_cols + delta_cols + gamma_p_cols,\n",
        "    }\n",
        "\n",
        "    print(f\"Found {len(alpha_pp_cols)} Alpha'' features.\")\n",
        "    print(f\"Found {len(delta_cols)} Delta features.\")\n",
        "    print(f\"Found {len(gamma_p_cols)} Gamma' features.\")\n",
        "\n",
        "    if not alpha_pp_cols or not delta_cols or not gamma_p_cols:\n",
        "        print(\"FATAL ERROR: Could not find all feature columns.\")\n",
        "        return None, None\n",
        "\n",
        "    return df, feature_sets\n",
        "\n",
        "# --- PART 3: Classification Task Function (UPDATED) ---\n",
        "\n",
        "def run_classification_task(df, target_label, feature_set_name, feature_cols, model_name, model_instance):\n",
        "    \"\"\"\n",
        "    Runs a classification pipeline for a specific Model + Feature Set combination.\n",
        "    Handles Label Encoding automatically for XGBoost.\n",
        "    \"\"\"\n",
        "    print(f\"\\nRunning: {model_name} | Target: {target_label} | Features: {feature_set_name}\")\n",
        "\n",
        "    # --- 1. Prepare Data ---\n",
        "    # --- 1. Prepare Data & Split (FIXED) ---\n",
        "    SPLIT_MAP_FILE = os.path.join(BASE_PATH, \"train_test_split_map.csv\")\n",
        "    if not os.path.exists(SPLIT_MAP_FILE):\n",
        "        print(\"CRITICAL ERROR: Split map not found! Please run alpha2.ipynb first.\")\n",
        "        return {}\n",
        "\n",
        "    # Load split map\n",
        "    df_split = pd.read_csv(SPLIT_MAP_FILE)\n",
        "    \n",
        "    # Ensure df has 'filename'\n",
        "    if 'filename' not in df.columns:\n",
        "         print(\"Error: 'filename' column missing from dataframe.\")\n",
        "         return {}\n",
        "\n",
        "    df_merged = pd.merge(df, df_split, on='filename', how='inner')\n",
        "    \n",
        "    # Separate into Train and Test DataFrames based on the map\n",
        "    df_train_set = df_merged[df_merged['split_group'] == 'TRAIN']\n",
        "    df_test_set = df_merged[df_merged['split_group'] == 'TEST']\n",
        "    \n",
        "    # Extract Features (X) and Target (y) for each set\n",
        "    X_train = df_train_set[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    y_train_raw = df_train_set[target_label]\n",
        "    \n",
        "    X_test = df_test_set[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    y_test_raw = df_test_set[target_label]\n",
        "\n",
        "    print(f\"   > Split Stats: Train={len(X_train)}, Test={len(X_test)}\")\n",
        "\n",
        "    # Encode Labels (Fit on ALL to ensure all classes are known)\n",
        "    le = LabelEncoder()\n",
        "    le.fit(pd.concat([y_train_raw, y_test_raw])) \n",
        "    \n",
        "    y_train = le.transform(y_train_raw)\n",
        "    y_test = le.transform(y_test_raw)\n",
        "    class_labels = [str(c) for c in le.classes_]\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', model_instance)\n",
        "    ])\n",
        "\n",
        "    # --- 4. Train ---\n",
        "    start_time = time.time()\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "    train_time = end_time - start_time\n",
        "\n",
        "    # --- 5. Evaluate ---\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # We pass target_names=class_labels so the report shows 'Chat', 'VoIP' etc.\n",
        "    # instead of 0, 1, 2.\n",
        "    report_dict = classification_report(\n",
        "        y_test, y_pred, target_names=class_labels, zero_division=0, output_dict=True\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': report_dict['weighted avg']['precision'],\n",
        "        'recall': report_dict['weighted avg']['recall'],\n",
        "        'f1_score': report_dict['weighted avg']['f1-score'],\n",
        "        'time': train_time,\n",
        "        'model_name': model_name\n",
        "    }\n",
        "\n",
        "    print(f\" > Acc: {metrics['accuracy']:.4f} | F1: {metrics['f1_score']:.4f} | Time: {train_time:.2f}s\")\n",
        "    return metrics\n",
        "\n",
        "# --- PART 4: Main Execution ---\n",
        "def main():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    df, feature_sets = load_data(EXPERIMENT_MODE)\n",
        "    if df is None: return\n",
        "\n",
        "    # Define tasks based on mode\n",
        "    if EXPERIMENT_MODE == \"FULL\":\n",
        "        tasks_to_run = ['binary_type', 'category', 'application']\n",
        "    else:\n",
        "        tasks_to_run = ['category', 'application']\n",
        "\n",
        "    # Storage: summary_results[task][model_name][feature_set] = metrics\n",
        "    summary_results = {}\n",
        "\n",
        "    # --- THE CHAMPIONSHIP LOOP ---\n",
        "    for task in tasks_to_run:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"--- STARTING TOURNAMENT FOR TARGET: {task} ---\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        task_results = [] # List to store flattened results for sorting\n",
        "\n",
        "        for model_name, model_inst in MODELS.items():\n",
        "            print(f\"\\n--- Evaluating Contender: {model_name} ---\")\n",
        "\n",
        "            for set_name, cols in feature_sets.items():\n",
        "                if not cols: continue\n",
        "\n",
        "                # Run the task\n",
        "                metrics = run_classification_task(df, task, set_name, cols, model_name, model_inst)\n",
        "\n",
        "                # Save results flatly for easy sorting\n",
        "                metrics['feature_set'] = set_name\n",
        "                task_results.append(metrics)\n",
        "\n",
        "        summary_results[task] = task_results\n",
        "\n",
        "    # --- Final Summary Report ---\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"--- FINAL CHAMPIONSHIP STANDINGS ({EXPERIMENT_MODE}) ---\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    for task, results_list in summary_results.items():\n",
        "        print(f\"--- Target: {task} ---\")\n",
        "\n",
        "        # Sort by Accuracy (Desc)\n",
        "        sorted_results = sorted(results_list, key=lambda x: x['accuracy'], reverse=True)\n",
        "\n",
        "        # Define Header\n",
        "        # M = Model, FS = Feature Set, Acc = Accuracy, F1 = F1-Score, T = Time\n",
        "        header = f\" {'Model':<15} | {'Feature Set':<25} | {'Acc %':<8} | {'F1 %':<8} | {'Time (s)':<8}\"\n",
        "        print(header)\n",
        "        print(\"-\" * len(header))\n",
        "\n",
        "        for res in sorted_results:\n",
        "            print(f\" {res['model_name']:<15} | {res['feature_set']:<25} | \"\n",
        "                  f\"{res['accuracy']*100:6.2f} | {res['f1_score']*100:6.2f} | \"\n",
        "                  f\"{res['time']:6.2f}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"--- Championship Finished ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"Please mount your Google Drive first!\")\n",
        "    else:\n",
        "        main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PESV v3 \"Championship\" Ablation Study (MULTI-MODEL) ---\n",
        "#\n",
        "# This script loads the final 'final_PESV_dataset_v3.csv'\n",
        "# and runs a \"championship\" ablation study comparing:\n",
        "# 1. Random Forest (Bagging)\n",
        "# 2. XGBoost (Boosting)\n",
        "# 3. SVM (Geometric/Hyperplane)\n",
        "#\n",
        "# It iterates through all Tasks -> Models -> Feature Sets automatically.\n",
        "\n",
        "print(\"--- Initializing PESV v3 Championship (Multi-Model) ---\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Try importing XGBoost; handle if missing\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except ImportError:\n",
        "    print(\"WARNING: XGBoost not installed. Skipping XGBoost.\")\n",
        "    HAS_XGB = False\n",
        "\n",
        "print(\"All libraries imported successfully.\")\n",
        "\n",
        "# --- PART 1: Configuration ---\n",
        "\n",
        "# --- !! SET YOUR EXPERIMENT MODE !! ---\n",
        "# \"FULL\"        - Runs on the full v3 dataset\n",
        "# \"VPN_ONLY\"    - Runs on only the VPN samples\n",
        "# \"NONVPN_ONLY\" - Runs on only the NonVPN samples\n",
        "EXPERIMENT_MODE = \"FULL\"\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/1 Skripsi/\"\n",
        "FINAL_PESV_FILE = os.path.join(BASE_PATH, \"final_PESV_dataset_v3.csv\")\n",
        "\n",
        "# --- DEFINE THE CONTENDERS ---\n",
        "MODELS = {\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"SVM\": SVC(\n",
        "        kernel='rbf',\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        probability=False # Set True only if you need predict_proba (slower)\n",
        "    )\n",
        "}\n",
        "\n",
        "# Add XGBoost if installed\n",
        "if HAS_XGB:\n",
        "    MODELS[\"XGBoost\"] = XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        # XGBoost handles multiclass automatically.\n",
        "        # We use default weights here for stability across different tasks.\n",
        "    )\n",
        "\n",
        "TEST_SET_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- PART 2: Load Data and Define Feature Sets ---\n",
        "\n",
        "def load_data(experiment_mode):\n",
        "    \"\"\"Loads and filters the dataset based on the experiment mode.\"\"\"\n",
        "    print(f\"\\n--- Loading Data for Mode: {experiment_mode} ---\")\n",
        "    if not os.path.exists(FINAL_PESV_FILE):\n",
        "        print(f\"FATAL ERROR: Could not find dataset at '{FINAL_PESV_FILE}'\")\n",
        "        return None, None\n",
        "\n",
        "    df_full = pd.read_csv(FINAL_PESV_FILE)\n",
        "\n",
        "    if experiment_mode == \"FULL\":\n",
        "        df = df_full\n",
        "    elif experiment_mode == \"VPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'VPN'].copy()\n",
        "    elif experiment_mode == \"NONVPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'NonVPN'].copy()\n",
        "    else:\n",
        "        print(f\"FATAL ERROR: Unknown experiment mode '{experiment_mode}'\")\n",
        "        return None, None\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"FATAL ERROR: The filtered dataset is empty.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Loaded dataset with shape: {df.shape}\")\n",
        "\n",
        "    # --- Define Feature Column Groups ---\n",
        "    all_cols = set(df.columns)\n",
        "\n",
        "    # 1. Find Alpha'' (\u03b1'') columns\n",
        "    alpha_pp_cols = sorted(list([c for c in all_cols if c.startswith('alpha_pp_')]))\n",
        "\n",
        "    # 2. Find Delta (\u03b4) columns\n",
        "    delta_cols_set = set([c for c in all_cols if\n",
        "                          c.startswith('c2s_') or\n",
        "                          c.startswith('s2c_') or\n",
        "                          c.startswith('flow_') or\n",
        "                          c.startswith('total_')])\n",
        "    delta_cols = sorted(list(delta_cols_set))\n",
        "\n",
        "    # 3. Find Gamma' (\u03b3') columns\n",
        "    gamma_p_cols_set = set([c for c in all_cols if c.startswith('burst_')])\n",
        "    gamma_p_cols = sorted(list(gamma_p_cols_set))\n",
        "\n",
        "    # Master list of feature sets\n",
        "    feature_sets = {\n",
        "        \"Alpha'' (\u03b1'') only\": alpha_pp_cols,\n",
        "        \"Delta (\u03b4) only\": delta_cols,\n",
        "        \"Gamma' (\u03b3') only\": gamma_p_cols,\n",
        "        \"Alpha'' + Delta\": alpha_pp_cols + delta_cols,\n",
        "        \"Alpha'' + Gamma'\": alpha_pp_cols + gamma_p_cols,\n",
        "        \"Delta + Gamma'\": delta_cols + gamma_p_cols,\n",
        "        \"Full (\u03b1'' + \u03b4 + \u03b3')\": alpha_pp_cols + delta_cols + gamma_p_cols,\n",
        "    }\n",
        "\n",
        "    print(f\"Found {len(alpha_pp_cols)} Alpha'' features.\")\n",
        "    print(f\"Found {len(delta_cols)} Delta features.\")\n",
        "    print(f\"Found {len(gamma_p_cols)} Gamma' features.\")\n",
        "\n",
        "    if not alpha_pp_cols or not delta_cols or not gamma_p_cols:\n",
        "        print(\"FATAL ERROR: Could not find all feature columns.\")\n",
        "        return None, None\n",
        "\n",
        "    return df, feature_sets\n",
        "\n",
        "# --- PART 3: Classification Task Function (UPDATED) ---\n",
        "\n",
        "def run_classification_task(df, target_label, feature_set_name, feature_cols, model_name, model_instance):\n",
        "    \"\"\"\n",
        "    Runs a classification pipeline for a specific Model + Feature Set combination.\n",
        "    Handles Label Encoding automatically for XGBoost.\n",
        "    \"\"\"\n",
        "    print(f\"\\nRunning: {model_name} | Target: {target_label} | Features: {feature_set_name}\")\n",
        "\n",
        "    # --- 1. Prepare Data ---\n",
        "    X = df[feature_cols]\n",
        "    y = df[target_label]\n",
        "\n",
        "    # Handle NaN/Inf\n",
        "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    # --- FIX: Encode Target Labels (Required for XGBoost) ---\n",
        "    # XGBoost crashes if y contains strings like 'Chat', 'VoIP'.\n",
        "    # We encode them to 0, 1, 2... here.\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    class_labels = [str(c) for c in le.classes_] # Save original names for report\n",
        "\n",
        "    # --- 2. Train/Test Split ---\n",
        "    # Note: We use y_encoded here instead of y\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_encoded, test_size=TEST_SET_SIZE, random_state=RANDOM_STATE, stratify=y_encoded\n",
        "    )\n",
        "\n",
        "    # --- 3. Create Pipeline ---\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', model_instance)\n",
        "    ])\n",
        "\n",
        "    # --- 4. Train ---\n",
        "    start_time = time.time()\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "    train_time = end_time - start_time\n",
        "\n",
        "    # --- 5. Evaluate ---\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # We pass target_names=class_labels so the report shows 'Chat', 'VoIP' etc.\n",
        "    # instead of 0, 1, 2.\n",
        "    report_dict = classification_report(\n",
        "        y_test, y_pred, target_names=class_labels, zero_division=0, output_dict=True\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': report_dict['weighted avg']['precision'],\n",
        "        'recall': report_dict['weighted avg']['recall'],\n",
        "        'f1_score': report_dict['weighted avg']['f1-score'],\n",
        "        'time': train_time,\n",
        "        'model_name': model_name\n",
        "    }\n",
        "\n",
        "    print(f\" > Acc: {metrics['accuracy']:.4f} | F1: {metrics['f1_score']:.4f} | Time: {train_time:.2f}s\")\n",
        "    return metrics\n",
        "\n",
        "# --- PART 4: Main Execution ---\n",
        "def main():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    df, feature_sets = load_data(EXPERIMENT_MODE)\n",
        "    if df is None: return\n",
        "\n",
        "    # Define tasks based on mode\n",
        "    if EXPERIMENT_MODE == \"FULL\":\n",
        "        tasks_to_run = ['binary_type', 'category', 'application']\n",
        "    else:\n",
        "        tasks_to_run = ['category', 'application']\n",
        "\n",
        "    # Storage: summary_results[task][model_name][feature_set] = metrics\n",
        "    summary_results = {}\n",
        "\n",
        "    # --- THE CHAMPIONSHIP LOOP ---\n",
        "    for task in tasks_to_run:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"--- STARTING TOURNAMENT FOR TARGET: {task} ---\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        task_results = [] # List to store flattened results for sorting\n",
        "\n",
        "        for model_name, model_inst in MODELS.items():\n",
        "            print(f\"\\n--- Evaluating Contender: {model_name} ---\")\n",
        "\n",
        "            for set_name, cols in feature_sets.items():\n",
        "                if not cols: continue\n",
        "\n",
        "                # Run the task\n",
        "                metrics = run_classification_task(df, task, set_name, cols, model_name, model_inst)\n",
        "\n",
        "                # Save results flatly for easy sorting\n",
        "                metrics['feature_set'] = set_name\n",
        "                task_results.append(metrics)\n",
        "\n",
        "        summary_results[task] = task_results\n",
        "\n",
        "    # --- Final Summary Report ---\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"--- FINAL CHAMPIONSHIP STANDINGS ({EXPERIMENT_MODE}) ---\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    for task, results_list in summary_results.items():\n",
        "        print(f\"--- Target: {task} ---\")\n",
        "\n",
        "        # Sort by Accuracy (Desc)\n",
        "        sorted_results = sorted(results_list, key=lambda x: x['accuracy'], reverse=True)\n",
        "\n",
        "        # Define Header\n",
        "        # M = Model, FS = Feature Set, Acc = Accuracy, F1 = F1-Score, T = Time\n",
        "        header = f\" {'Model':<15} | {'Feature Set':<25} | {'Acc %':<8} | {'F1 %':<8} | {'Time (s)':<8}\"\n",
        "        print(header)\n",
        "        print(\"-\" * len(header))\n",
        "\n",
        "        for res in sorted_results:\n",
        "            print(f\" {res['model_name']:<15} | {res['feature_set']:<25} | \"\n",
        "                  f\"{res['accuracy']*100:6.2f} | {res['f1_score']*100:6.2f} | \"\n",
        "                  f\"{res['time']:6.2f}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"--- Championship Finished ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"Please mount your Google Drive first!\")\n",
        "    else:\n",
        "        main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOwAl1zS8HIH",
        "outputId": "082f6908-5bf0-45a8-da5e-d678e84298f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing PESV v3 Championship (Multi-Model) ---\n",
            "All libraries imported successfully.\n",
            "\n",
            "--- Loading Data for Mode: FULL ---\n",
            "Loaded dataset with shape: (9542, 208)\n",
            "Found 128 Alpha'' features.\n",
            "Found 40 Delta features.\n",
            "Found 36 Gamma' features.\n",
            "\n",
            "================================================================================\n",
            "--- STARTING TOURNAMENT FOR TARGET: binary_type ---\n",
            "================================================================================\n",
            "\n",
            "--- Evaluating Contender: Random Forest ---\n",
            "\n",
            "Running: Random Forest | Target: binary_type | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.9345 | F1: 0.9340 | Time: 1.67s\n",
            "\n",
            "Running: Random Forest | Target: binary_type | Features: Delta (\u03b4) only\n",
            " > Acc: 0.9623 | F1: 0.9619 | Time: 1.13s\n",
            "\n",
            "Running: Random Forest | Target: binary_type | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.9497 | F1: 0.9489 | Time: 1.17s\n",
            "\n",
            "Running: Random Forest | Target: binary_type | Features: Alpha'' + Delta\n",
            " > Acc: 0.9644 | F1: 0.9644 | Time: 1.70s\n",
            "\n",
            "Running: Random Forest | Target: binary_type | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.9665 | F1: 0.9665 | Time: 3.00s\n",
            "\n",
            "Running: Random Forest | Target: binary_type | Features: Delta + Gamma'\n",
            " > Acc: 0.9644 | F1: 0.9641 | Time: 1.72s\n",
            "\n",
            "Running: Random Forest | Target: binary_type | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.9701 | F1: 0.9701 | Time: 2.13s\n",
            "\n",
            "--- Evaluating Contender: SVM ---\n",
            "\n",
            "Running: SVM | Target: binary_type | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.9345 | F1: 0.9372 | Time: 1.05s\n",
            "\n",
            "Running: SVM | Target: binary_type | Features: Delta (\u03b4) only\n",
            " > Acc: 0.7779 | F1: 0.7988 | Time: 2.21s\n",
            "\n",
            "Running: SVM | Target: binary_type | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.8308 | F1: 0.7973 | Time: 3.66s\n",
            "\n",
            "Running: SVM | Target: binary_type | Features: Alpha'' + Delta\n",
            " > Acc: 0.9382 | F1: 0.9407 | Time: 2.34s\n",
            "\n",
            "Running: SVM | Target: binary_type | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.9387 | F1: 0.9413 | Time: 1.86s\n",
            "\n",
            "Running: SVM | Target: binary_type | Features: Delta + Gamma'\n",
            " > Acc: 0.7774 | F1: 0.7982 | Time: 3.72s\n",
            "\n",
            "Running: SVM | Target: binary_type | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.9382 | F1: 0.9408 | Time: 1.87s\n",
            "\n",
            "--- Evaluating Contender: XGBoost ---\n",
            "\n",
            "Running: XGBoost | Target: binary_type | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.9345 | F1: 0.9344 | Time: 1.59s\n",
            "\n",
            "Running: XGBoost | Target: binary_type | Features: Delta (\u03b4) only\n",
            " > Acc: 0.9701 | F1: 0.9701 | Time: 0.36s\n",
            "\n",
            "Running: XGBoost | Target: binary_type | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.9607 | F1: 0.9605 | Time: 0.36s\n",
            "\n",
            "Running: XGBoost | Target: binary_type | Features: Alpha'' + Delta\n",
            " > Acc: 0.9712 | F1: 0.9713 | Time: 1.20s\n",
            "\n",
            "Running: XGBoost | Target: binary_type | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.9612 | F1: 0.9612 | Time: 1.24s\n",
            "\n",
            "Running: XGBoost | Target: binary_type | Features: Delta + Gamma'\n",
            " > Acc: 0.9722 | F1: 0.9722 | Time: 0.70s\n",
            "\n",
            "Running: XGBoost | Target: binary_type | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.9712 | F1: 0.9712 | Time: 1.53s\n",
            "\n",
            "================================================================================\n",
            "--- STARTING TOURNAMENT FOR TARGET: category ---\n",
            "================================================================================\n",
            "\n",
            "--- Evaluating Contender: Random Forest ---\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.7748 | F1: 0.7529 | Time: 1.52s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Delta (\u03b4) only\n",
            " > Acc: 0.7585 | F1: 0.7451 | Time: 1.25s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.7355 | F1: 0.7198 | Time: 1.53s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Alpha'' + Delta\n",
            " > Acc: 0.8109 | F1: 0.7912 | Time: 3.08s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.8135 | F1: 0.7931 | Time: 1.87s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Delta + Gamma'\n",
            " > Acc: 0.7543 | F1: 0.7407 | Time: 1.71s\n",
            "\n",
            "Running: Random Forest | Target: category | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.8140 | F1: 0.7940 | Time: 2.19s\n",
            "\n",
            "--- Evaluating Contender: SVM ---\n",
            "\n",
            "Running: SVM | Target: category | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.7444 | F1: 0.7274 | Time: 2.87s\n",
            "\n",
            "Running: SVM | Target: category | Features: Delta (\u03b4) only\n",
            " > Acc: 0.5511 | F1: 0.5024 | Time: 5.44s\n",
            "\n",
            "Running: SVM | Target: category | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.2949 | F1: 0.2038 | Time: 6.65s\n",
            "\n",
            "Running: SVM | Target: category | Features: Alpha'' + Delta\n",
            " > Acc: 0.7491 | F1: 0.7322 | Time: 3.90s\n",
            "\n",
            "Running: SVM | Target: category | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.7528 | F1: 0.7359 | Time: 3.23s\n",
            "\n",
            "Running: SVM | Target: category | Features: Delta + Gamma'\n",
            " > Acc: 0.5385 | F1: 0.4966 | Time: 6.46s\n",
            "\n",
            "Running: SVM | Target: category | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.7533 | F1: 0.7356 | Time: 4.59s\n",
            "\n",
            "--- Evaluating Contender: XGBoost ---\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.7737 | F1: 0.7522 | Time: 6.11s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Delta (\u03b4) only\n",
            " > Acc: 0.7674 | F1: 0.7532 | Time: 1.90s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.7444 | F1: 0.7296 | Time: 1.92s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Alpha'' + Delta\n",
            " > Acc: 0.8146 | F1: 0.7933 | Time: 7.91s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.8146 | F1: 0.7941 | Time: 5.47s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Delta + Gamma'\n",
            " > Acc: 0.7685 | F1: 0.7548 | Time: 5.56s\n",
            "\n",
            "Running: XGBoost | Target: category | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.8125 | F1: 0.7922 | Time: 7.59s\n",
            "\n",
            "================================================================================\n",
            "--- STARTING TOURNAMENT FOR TARGET: application ---\n",
            "================================================================================\n",
            "\n",
            "--- Evaluating Contender: Random Forest ---\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.7475 | F1: 0.7535 | Time: 1.39s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Delta (\u03b4) only\n",
            " > Acc: 0.6894 | F1: 0.6990 | Time: 1.20s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.6679 | F1: 0.6762 | Time: 2.20s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Alpha'' + Delta\n",
            " > Acc: 0.7638 | F1: 0.7711 | Time: 2.22s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.7632 | F1: 0.7707 | Time: 1.65s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Delta + Gamma'\n",
            " > Acc: 0.6857 | F1: 0.6949 | Time: 1.58s\n",
            "\n",
            "Running: Random Forest | Target: application | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.7658 | F1: 0.7731 | Time: 2.08s\n",
            "\n",
            "--- Evaluating Contender: SVM ---\n",
            "\n",
            "Running: SVM | Target: application | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.7135 | F1: 0.7229 | Time: 2.62s\n",
            "\n",
            "Running: SVM | Target: application | Features: Delta (\u03b4) only\n",
            " > Acc: 0.4924 | F1: 0.4987 | Time: 6.38s\n",
            "\n",
            "Running: SVM | Target: application | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.1744 | F1: 0.1247 | Time: 7.82s\n",
            "\n",
            "Running: SVM | Target: application | Features: Alpha'' + Delta\n",
            " > Acc: 0.7145 | F1: 0.7235 | Time: 3.20s\n",
            "\n",
            "Running: SVM | Target: application | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.7161 | F1: 0.7250 | Time: 3.10s\n",
            "\n",
            "Running: SVM | Target: application | Features: Delta + Gamma'\n",
            " > Acc: 0.4825 | F1: 0.4891 | Time: 7.59s\n",
            "\n",
            "Running: SVM | Target: application | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.7145 | F1: 0.7234 | Time: 3.71s\n",
            "\n",
            "--- Evaluating Contender: XGBoost ---\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Alpha'' (\u03b1'') only\n",
            " > Acc: 0.8193 | F1: 0.7830 | Time: 4.66s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Delta (\u03b4) only\n",
            " > Acc: 0.7842 | F1: 0.7538 | Time: 1.80s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Gamma' (\u03b3') only\n",
            " > Acc: 0.7606 | F1: 0.7285 | Time: 1.77s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Alpha'' + Delta\n",
            " > Acc: 0.8402 | F1: 0.8082 | Time: 6.14s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Alpha'' + Gamma'\n",
            " > Acc: 0.8428 | F1: 0.8097 | Time: 4.85s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Delta + Gamma'\n",
            " > Acc: 0.7831 | F1: 0.7522 | Time: 3.21s\n",
            "\n",
            "Running: XGBoost | Target: application | Features: Full (\u03b1'' + \u03b4 + \u03b3')\n",
            " > Acc: 0.8402 | F1: 0.8082 | Time: 7.90s\n",
            "\n",
            "================================================================================\n",
            "--- FINAL CHAMPIONSHIP STANDINGS (FULL) ---\n",
            "================================================================================\n",
            "\n",
            "--- Target: binary_type ---\n",
            " Model           | Feature Set               | Acc %    | F1 %     | Time (s)\n",
            "-----------------------------------------------------------------------------\n",
            " XGBoost         | Delta + Gamma'            |  97.22 |  97.22 |   0.70\n",
            " XGBoost         | Alpha'' + Delta           |  97.12 |  97.13 |   1.20\n",
            " XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')       |  97.12 |  97.12 |   1.53\n",
            " Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')       |  97.01 |  97.01 |   2.13\n",
            " XGBoost         | Delta (\u03b4) only            |  97.01 |  97.01 |   0.36\n",
            " Random Forest   | Alpha'' + Gamma'          |  96.65 |  96.65 |   3.00\n",
            " Random Forest   | Alpha'' + Delta           |  96.44 |  96.44 |   1.70\n",
            " Random Forest   | Delta + Gamma'            |  96.44 |  96.41 |   1.72\n",
            " Random Forest   | Delta (\u03b4) only            |  96.23 |  96.19 |   1.13\n",
            " XGBoost         | Alpha'' + Gamma'          |  96.12 |  96.12 |   1.24\n",
            " XGBoost         | Gamma' (\u03b3') only          |  96.07 |  96.05 |   0.36\n",
            " Random Forest   | Gamma' (\u03b3') only          |  94.97 |  94.89 |   1.17\n",
            " SVM             | Alpha'' + Gamma'          |  93.87 |  94.13 |   1.86\n",
            " SVM             | Alpha'' + Delta           |  93.82 |  94.07 |   2.34\n",
            " SVM             | Full (\u03b1'' + \u03b4 + \u03b3')       |  93.82 |  94.08 |   1.87\n",
            " Random Forest   | Alpha'' (\u03b1'') only        |  93.45 |  93.40 |   1.67\n",
            " SVM             | Alpha'' (\u03b1'') only        |  93.45 |  93.72 |   1.05\n",
            " XGBoost         | Alpha'' (\u03b1'') only        |  93.45 |  93.44 |   1.59\n",
            " SVM             | Gamma' (\u03b3') only          |  83.08 |  79.73 |   3.66\n",
            " SVM             | Delta (\u03b4) only            |  77.79 |  79.88 |   2.21\n",
            " SVM             | Delta + Gamma'            |  77.74 |  79.82 |   3.72\n",
            "\n",
            "\n",
            "--- Target: category ---\n",
            " Model           | Feature Set               | Acc %    | F1 %     | Time (s)\n",
            "-----------------------------------------------------------------------------\n",
            " XGBoost         | Alpha'' + Delta           |  81.46 |  79.33 |   7.91\n",
            " XGBoost         | Alpha'' + Gamma'          |  81.46 |  79.41 |   5.47\n",
            " Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')       |  81.40 |  79.40 |   2.19\n",
            " Random Forest   | Alpha'' + Gamma'          |  81.35 |  79.31 |   1.87\n",
            " XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')       |  81.25 |  79.22 |   7.59\n",
            " Random Forest   | Alpha'' + Delta           |  81.09 |  79.12 |   3.08\n",
            " Random Forest   | Alpha'' (\u03b1'') only        |  77.48 |  75.29 |   1.52\n",
            " XGBoost         | Alpha'' (\u03b1'') only        |  77.37 |  75.22 |   6.11\n",
            " XGBoost         | Delta + Gamma'            |  76.85 |  75.48 |   5.56\n",
            " XGBoost         | Delta (\u03b4) only            |  76.74 |  75.32 |   1.90\n",
            " Random Forest   | Delta (\u03b4) only            |  75.85 |  74.51 |   1.25\n",
            " Random Forest   | Delta + Gamma'            |  75.43 |  74.07 |   1.71\n",
            " SVM             | Full (\u03b1'' + \u03b4 + \u03b3')       |  75.33 |  73.56 |   4.59\n",
            " SVM             | Alpha'' + Gamma'          |  75.28 |  73.59 |   3.23\n",
            " SVM             | Alpha'' + Delta           |  74.91 |  73.22 |   3.90\n",
            " SVM             | Alpha'' (\u03b1'') only        |  74.44 |  72.74 |   2.87\n",
            " XGBoost         | Gamma' (\u03b3') only          |  74.44 |  72.96 |   1.92\n",
            " Random Forest   | Gamma' (\u03b3') only          |  73.55 |  71.98 |   1.53\n",
            " SVM             | Delta (\u03b4) only            |  55.11 |  50.24 |   5.44\n",
            " SVM             | Delta + Gamma'            |  53.85 |  49.66 |   6.46\n",
            " SVM             | Gamma' (\u03b3') only          |  29.49 |  20.38 |   6.65\n",
            "\n",
            "\n",
            "--- Target: application ---\n",
            " Model           | Feature Set               | Acc %    | F1 %     | Time (s)\n",
            "-----------------------------------------------------------------------------\n",
            " XGBoost         | Alpha'' + Gamma'          |  84.28 |  80.97 |   4.85\n",
            " XGBoost         | Alpha'' + Delta           |  84.02 |  80.82 |   6.14\n",
            " XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')       |  84.02 |  80.82 |   7.90\n",
            " XGBoost         | Alpha'' (\u03b1'') only        |  81.93 |  78.30 |   4.66\n",
            " XGBoost         | Delta (\u03b4) only            |  78.42 |  75.38 |   1.80\n",
            " XGBoost         | Delta + Gamma'            |  78.31 |  75.22 |   3.21\n",
            " Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')       |  76.58 |  77.31 |   2.08\n",
            " Random Forest   | Alpha'' + Delta           |  76.38 |  77.11 |   2.22\n",
            " Random Forest   | Alpha'' + Gamma'          |  76.32 |  77.07 |   1.65\n",
            " XGBoost         | Gamma' (\u03b3') only          |  76.06 |  72.85 |   1.77\n",
            " Random Forest   | Alpha'' (\u03b1'') only        |  74.75 |  75.35 |   1.39\n",
            " SVM             | Alpha'' + Gamma'          |  71.61 |  72.50 |   3.10\n",
            " SVM             | Alpha'' + Delta           |  71.45 |  72.35 |   3.20\n",
            " SVM             | Full (\u03b1'' + \u03b4 + \u03b3')       |  71.45 |  72.34 |   3.71\n",
            " SVM             | Alpha'' (\u03b1'') only        |  71.35 |  72.29 |   2.62\n",
            " Random Forest   | Delta (\u03b4) only            |  68.94 |  69.90 |   1.20\n",
            " Random Forest   | Delta + Gamma'            |  68.57 |  69.49 |   1.58\n",
            " Random Forest   | Gamma' (\u03b3') only          |  66.79 |  67.62 |   2.20\n",
            " SVM             | Delta (\u03b4) only            |  49.24 |  49.87 |   6.38\n",
            " SVM             | Delta + Gamma'            |  48.25 |  48.91 |   7.59\n",
            " SVM             | Gamma' (\u03b3') only          |  17.44 |  12.47 |   7.82\n",
            "\n",
            "\n",
            "--- Championship Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PESV v3 \"Championship\" with Hyperparameter Tuning ---\n",
        "#\n",
        "# Models: Random Forest vs. XGBoost\n",
        "# Features: Grid Search for best parameters\n",
        "# Metrics: Accuracy, Weighted F1, MACRO F1 (Crucial for imbalance)\n",
        "\n",
        "print(\"--- Initializing PESV v3 Tuned Championship ---\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Try importing XGBoost\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except ImportError:\n",
        "    print(\"WARNING: XGBoost not installed. Skipping XGBoost.\")\n",
        "    HAS_XGB = False\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- PART 1: Configuration ---\n",
        "\n",
        "EXPERIMENT_MODE = \"VPN_ONLY\"\n",
        "BASE_PATH = \"/content/drive/MyDrive/1 Skripsi/\"\n",
        "FINAL_PESV_FILE = os.path.join(BASE_PATH, \"VPNOnly-final_PESV_dataset_v3.csv\")\n",
        "# FINAL_PESV_FILE = os.path.join(BASE_PATH, \"final_PESV_dataset_v3.csv\") # For FULL mode\n",
        "\n",
        "TEST_SET_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "CV_FOLDS = 3  # Number of cross-validation folds\n",
        "N_ITER_SEARCH = 10 # How many random parameter combinations to try per model\n",
        "\n",
        "# --- PART 2: Model & Parameter Definitions ---\n",
        "\n",
        "# We define a dictionary of models and their hyperparameter grids\n",
        "# Note: Parameters must be prefixed with 'classifier__' because they are inside a Pipeline\n",
        "\n",
        "MODEL_CONFIGS = {\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\"),\n",
        "        \"params\": {\n",
        "            \"classifier__n_estimators\": [100, 200, 300],\n",
        "            \"classifier__max_depth\": [None, 10, 20, 30],\n",
        "            \"classifier__min_samples_split\": [2, 5, 10],\n",
        "            \"classifier__criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "if HAS_XGB:\n",
        "    MODEL_CONFIGS[\"XGBoost\"] = {\n",
        "        \"model\": XGBClassifier(random_state=RANDOM_STATE, eval_metric='mlogloss'),\n",
        "        \"params\": {\n",
        "            \"classifier__n_estimators\": [100, 200, 300],\n",
        "            \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
        "            \"classifier__max_depth\": [3, 6, 10],\n",
        "            \"classifier__subsample\": [0.8, 1.0]\n",
        "        }\n",
        "    }\n",
        "\n",
        "# --- PART 3: Data Loading Helper ---\n",
        "\n",
        "def load_data(experiment_mode):\n",
        "    print(f\"\\n--- Loading Data for Mode: {experiment_mode} ---\")\n",
        "    if not os.path.exists(FINAL_PESV_FILE):\n",
        "        print(f\"FATAL ERROR: Could not find dataset at '{FINAL_PESV_FILE}'\")\n",
        "        return None, None\n",
        "\n",
        "    df_full = pd.read_csv(FINAL_PESV_FILE)\n",
        "\n",
        "    if experiment_mode == \"FULL\":\n",
        "        df = df_full\n",
        "    elif experiment_mode == \"VPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'VPN'].copy()\n",
        "    elif experiment_mode == \"NONVPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'NonVPN'].copy()\n",
        "    else:\n",
        "        print(f\"ERROR: Unknown mode {experiment_mode}\")\n",
        "        return None, None\n",
        "\n",
        "    if df.empty: return None, None\n",
        "\n",
        "    # Define Feature Columns\n",
        "    all_cols = set(df.columns)\n",
        "    alpha_cols = sorted([c for c in all_cols if c.startswith('alpha_pp_')])\n",
        "    delta_cols = sorted([c for c in all_cols if c.startswith(('c2s_', 's2c_', 'flow_', 'total_'))])\n",
        "    gamma_cols = sorted([c for c in all_cols if c.startswith('burst_')])\n",
        "\n",
        "    feature_sets = {\n",
        "        \"Alpha'' (\u03b1'') only\": alpha_cols,\n",
        "        \"Delta (\u03b4) only\": delta_cols,\n",
        "        \"Gamma' (\u03b3') only\": gamma_cols,\n",
        "        \"Alpha'' + Delta\": alpha_cols + delta_cols,\n",
        "        \"Alpha'' + Gamma'\": alpha_cols + gamma_cols,\n",
        "        \"Delta + Gamma'\": delta_cols + gamma_cols,\n",
        "        \"Full (\u03b1'' + \u03b4 + \u03b3')\": alpha_cols + delta_cols + gamma_cols,\n",
        "    }\n",
        "\n",
        "    return df, feature_sets\n",
        "\n",
        "# --- PART 4: Tuned Classification Task ---\n",
        "\n",
        "def run_tuned_classification(df, target_label, feature_set_name, feature_cols, model_name, config):\n",
        "    \"\"\"\n",
        "    Runs RandomizedSearchCV to find best params, then evaluates on Test set.\n",
        "    \"\"\"\n",
        "    print(f\" > Training {model_name} on {feature_set_name} ({len(feature_cols)} feats)...\")\n",
        "\n",
        "    X = df[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    y = df[target_label]\n",
        "\n",
        "    # Encode labels (Required for XGBoost)\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    class_names = [str(c) for c in le.classes_]\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_encoded, test_size=TEST_SET_SIZE, random_state=RANDOM_STATE, stratify=y_encoded\n",
        "    )\n",
        "\n",
        "    # Pipeline\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', config[\"model\"])\n",
        "    ])\n",
        "\n",
        "    # Hyperparameter Tuning (RandomizedSearchCV)\n",
        "    # We use f1_macro for scoring because of the class imbalance (Skype vs Netflix)\n",
        "    search = RandomizedSearchCV(\n",
        "        pipeline,\n",
        "        param_distributions=config[\"params\"],\n",
        "        n_iter=N_ITER_SEARCH,\n",
        "        scoring='f1_macro',\n",
        "        cv=CV_FOLDS,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    search.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    best_model = search.best_estimator_\n",
        "    best_params = search.best_params_\n",
        "\n",
        "    # Predict\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Metrics extraction\n",
        "    report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
        "\n",
        "    metrics = {\n",
        "        'model': model_name,\n",
        "        'feature_set': feature_set_name,\n",
        "        'accuracy': report['accuracy'],\n",
        "\n",
        "        # Weighted Metrics (Biased towards Skype/Majority)\n",
        "        'f1_weighted': report['weighted avg']['f1-score'],\n",
        "        'prec_weighted': report['weighted avg']['precision'],\n",
        "        'rec_weighted': report['weighted avg']['recall'],\n",
        "\n",
        "        # Macro Metrics (Treats Netflix same as Skype - Good for Imbalance)\n",
        "        'f1_macro': report['macro avg']['f1-score'],\n",
        "        'prec_macro': report['macro avg']['precision'],\n",
        "        'rec_macro': report['macro avg']['recall'],\n",
        "\n",
        "        'time': end_time - start_time,\n",
        "        'best_params': str(best_params).replace(\"classifier__\", \"\") # Clean string\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# --- PART 5: Main Loop ---\n",
        "\n",
        "def main():\n",
        "    df, feature_sets = load_data(EXPERIMENT_MODE)\n",
        "    if df is None: return\n",
        "\n",
        "    tasks = ['category', 'application']\n",
        "    summary_results = {}\n",
        "\n",
        "    for task in tasks:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"--- TUNING AND EVALUATING TARGET: {task} ---\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        task_metrics = []\n",
        "\n",
        "        for model_name, config in MODEL_CONFIGS.items():\n",
        "            for fs_name, fs_cols in feature_sets.items():\n",
        "                if not fs_cols: continue\n",
        "\n",
        "                # Run Logic\n",
        "                m = run_tuned_classification(df, task, fs_name, fs_cols, model_name, config)\n",
        "                task_metrics.append(m)\n",
        "\n",
        "        summary_results[task] = task_metrics\n",
        "\n",
        "    # ... (Keep the training loops above) ...\n",
        "\n",
        "    # --- Final Reporting (REPLACED) ---\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"--- FINAL TUNED CHAMPIONSHIP RESULTS ({EXPERIMENT_MODE}) ---\")\n",
        "    print(f\"{'='*100}\\n\")\n",
        "\n",
        "    for task, results in summary_results.items():\n",
        "        print(f\"--- Target: {task} ---\")\n",
        "\n",
        "        # Sort by Macro F1\n",
        "        sorted_res = sorted(results, key=lambda x: x['f1_macro'], reverse=True)\n",
        "\n",
        "        # 1. Print the Summary Table\n",
        "        print(f\"{'Model':<15} | {'Feature Set':<22} | {'Acc':<6} | {'F1(W)':<6} | {'F1(Mac)':<8} | {'Time':<5}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for r in sorted_res:\n",
        "            print(f\"{r['model']:<15} | {r['feature_set']:<22} | \"\n",
        "                  f\"{r['accuracy']:.4f} | {r['f1_weighted']:.4f} | {r['f1_macro']:.4f}   | \"\n",
        "                  f\"{r['time']:<5.1f}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # 2. Print FULL Parameters for Top 3 Models\n",
        "        print(f\"--- \ud83c\udfc6 Top 3 Models for {task} (Full Parameters) ---\")\n",
        "        for i, r in enumerate(sorted_res[:3]):\n",
        "            print(f\"{i+1}. {r['model']} [{r['feature_set']}]\")\n",
        "            print(f\"   Accuracy: {r['accuracy']:.4f} | Macro F1: {r['f1_macro']:.4f}\")\n",
        "            print(f\"   Best Params: {r['best_params']}\") # Prints the full string\n",
        "            print(\"-\" * 50)\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "s_8SPhYxNn4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891196e6-a50c-4910-9715-81f6eb27b88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing PESV v3 Tuned Championship ---\n",
            "\n",
            "--- Loading Data for Mode: VPN_ONLY ---\n",
            "\n",
            "================================================================================\n",
            "--- TUNING AND EVALUATING TARGET: category ---\n",
            "================================================================================\n",
            " > Training Random Forest on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training Random Forest on Delta (\u03b4) only (40 feats)...\n",
            " > Training Random Forest on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training Random Forest on Alpha'' + Delta (168 feats)...\n",
            " > Training Random Forest on Alpha'' + Gamma' (164 feats)...\n",
            " > Training Random Forest on Delta + Gamma' (76 feats)...\n",
            " > Training Random Forest on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            " > Training XGBoost on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training XGBoost on Delta (\u03b4) only (40 feats)...\n",
            " > Training XGBoost on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training XGBoost on Alpha'' + Delta (168 feats)...\n",
            " > Training XGBoost on Alpha'' + Gamma' (164 feats)...\n",
            " > Training XGBoost on Delta + Gamma' (76 feats)...\n",
            " > Training XGBoost on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            "\n",
            "================================================================================\n",
            "--- TUNING AND EVALUATING TARGET: application ---\n",
            "================================================================================\n",
            " > Training Random Forest on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training Random Forest on Delta (\u03b4) only (40 feats)...\n",
            " > Training Random Forest on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training Random Forest on Alpha'' + Delta (168 feats)...\n",
            " > Training Random Forest on Alpha'' + Gamma' (164 feats)...\n",
            " > Training Random Forest on Delta + Gamma' (76 feats)...\n",
            " > Training Random Forest on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            " > Training XGBoost on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training XGBoost on Delta (\u03b4) only (40 feats)...\n",
            " > Training XGBoost on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training XGBoost on Alpha'' + Delta (168 feats)...\n",
            " > Training XGBoost on Alpha'' + Gamma' (164 feats)...\n",
            " > Training XGBoost on Delta + Gamma' (76 feats)...\n",
            " > Training XGBoost on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            "\n",
            "====================================================================================================\n",
            "--- FINAL TUNED CHAMPIONSHIP RESULTS (VPN_ONLY) ---\n",
            "====================================================================================================\n",
            "\n",
            "--- Target: category ---\n",
            "Model           | Feature Set            | Acc    | F1(W)  | F1(Mac)  | Time \n",
            "--------------------------------------------------------------------------------\n",
            "Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.9448 | 0.9451 | 0.9284   | 54.2 \n",
            "XGBoost         | Alpha'' + Gamma'       | 0.9448 | 0.9448 | 0.9268   | 288.5\n",
            "Random Forest   | Delta + Gamma'         | 0.9371 | 0.9371 | 0.9229   | 42.1 \n",
            "XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.9429 | 0.9431 | 0.9219   | 350.3\n",
            "XGBoost         | Delta + Gamma'         | 0.9410 | 0.9408 | 0.9202   | 161.5\n",
            "XGBoost         | Alpha'' + Delta        | 0.9352 | 0.9343 | 0.9187   | 298.6\n",
            "XGBoost         | Delta (\u03b4) only         | 0.9429 | 0.9427 | 0.9183   | 92.5 \n",
            "Random Forest   | Alpha'' + Gamma'       | 0.9371 | 0.9373 | 0.9177   | 48.7 \n",
            "Random Forest   | Alpha'' + Delta        | 0.9238 | 0.9239 | 0.9149   | 54.2 \n",
            "Random Forest   | Delta (\u03b4) only         | 0.9410 | 0.9409 | 0.9140   | 37.8 \n",
            "XGBoost         | Alpha'' (\u03b1'') only     | 0.9029 | 0.9025 | 0.8942   | 250.4\n",
            "XGBoost         | Gamma' (\u03b3') only       | 0.9086 | 0.9086 | 0.8923   | 88.6 \n",
            "Random Forest   | Alpha'' (\u03b1'') only     | 0.8990 | 0.8978 | 0.8883   | 48.6 \n",
            "Random Forest   | Gamma' (\u03b3') only       | 0.9010 | 0.9006 | 0.8789   | 36.0 \n",
            "\n",
            "\n",
            "--- \ud83c\udfc6 Top 3 Models for category (Full Parameters) ---\n",
            "1. Random Forest [Full (\u03b1'' + \u03b4 + \u03b3')]\n",
            "   Accuracy: 0.9448 | Macro F1: 0.9284\n",
            "   Best Params: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': None, 'criterion': 'gini'}\n",
            "--------------------------------------------------\n",
            "2. XGBoost [Alpha'' + Gamma']\n",
            "   Accuracy: 0.9448 | Macro F1: 0.9268\n",
            "   Best Params: {'subsample': 0.8, 'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.2}\n",
            "--------------------------------------------------\n",
            "3. Random Forest [Delta + Gamma']\n",
            "   Accuracy: 0.9371 | Macro F1: 0.9229\n",
            "   Best Params: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 20, 'criterion': 'entropy'}\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "--- Target: application ---\n",
            "Model           | Feature Set            | Acc    | F1(W)  | F1(Mac)  | Time \n",
            "--------------------------------------------------------------------------------\n",
            "XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.9124 | 0.9092 | 0.8209   | 377.3\n",
            "Random Forest   | Alpha'' (\u03b1'') only     | 0.8952 | 0.8966 | 0.8181   | 43.4 \n",
            "XGBoost         | Alpha'' + Gamma'       | 0.9086 | 0.9051 | 0.8144   | 298.3\n",
            "XGBoost         | Delta + Gamma'         | 0.9238 | 0.9219 | 0.8104   | 197.3\n",
            "XGBoost         | Alpha'' + Delta        | 0.9067 | 0.9027 | 0.8052   | 299.5\n",
            "Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.9048 | 0.9039 | 0.8047   | 51.3 \n",
            "Random Forest   | Alpha'' + Gamma'       | 0.8990 | 0.8974 | 0.8043   | 47.5 \n",
            "XGBoost         | Delta (\u03b4) only         | 0.9086 | 0.9041 | 0.8005   | 108.4\n",
            "Random Forest   | Delta (\u03b4) only         | 0.9029 | 0.9020 | 0.7968   | 33.9 \n",
            "Random Forest   | Delta + Gamma'         | 0.9162 | 0.9098 | 0.7941   | 43.1 \n",
            "Random Forest   | Alpha'' + Delta        | 0.9010 | 0.8968 | 0.7915   | 44.3 \n",
            "XGBoost         | Alpha'' (\u03b1'') only     | 0.8838 | 0.8833 | 0.7897   | 229.8\n",
            "XGBoost         | Gamma' (\u03b3') only       | 0.8895 | 0.8851 | 0.7667   | 110.3\n",
            "Random Forest   | Gamma' (\u03b3') only       | 0.8743 | 0.8674 | 0.7436   | 36.8 \n",
            "\n",
            "\n",
            "--- \ud83c\udfc6 Top 3 Models for application (Full Parameters) ---\n",
            "1. XGBoost [Full (\u03b1'' + \u03b4 + \u03b3')]\n",
            "   Accuracy: 0.9124 | Macro F1: 0.8209\n",
            "   Best Params: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.2}\n",
            "--------------------------------------------------\n",
            "2. Random Forest [Alpha'' (\u03b1'') only]\n",
            "   Accuracy: 0.8952 | Macro F1: 0.8181\n",
            "   Best Params: {'n_estimators': 300, 'min_samples_split': 5, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "--------------------------------------------------\n",
            "3. XGBoost [Alpha'' + Gamma']\n",
            "   Accuracy: 0.9086 | Macro F1: 0.8144\n",
            "   Best Params: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.2}\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PESV v3 \"Championship\" with Hyperparameter Tuning ---\n",
        "#\n",
        "# Models: Random Forest vs. XGBoost\n",
        "# Features: Grid Search for best parameters\n",
        "# Metrics: Accuracy, Weighted F1, MACRO F1 (Crucial for imbalance)\n",
        "\n",
        "print(\"--- Initializing PESV v3 Tuned Championship ---\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Try importing XGBoost\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except ImportError:\n",
        "    print(\"WARNING: XGBoost not installed. Skipping XGBoost.\")\n",
        "    HAS_XGB = False\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- PART 1: Configuration ---\n",
        "\n",
        "EXPERIMENT_MODE = \"FULL\"\n",
        "BASE_PATH = \"/content/drive/MyDrive/1 Skripsi/\"\n",
        "FINAL_PESV_FILE = os.path.join(BASE_PATH, \"final_PESV_dataset_v3.csv\")\n",
        "# FINAL_PESV_FILE = os.path.join(BASE_PATH, \"final_PESV_dataset_v3.csv\") # For FULL mode\n",
        "\n",
        "TEST_SET_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "CV_FOLDS = 3  # Number of cross-validation folds\n",
        "N_ITER_SEARCH = 10 # How many random parameter combinations to try per model\n",
        "\n",
        "# --- PART 2: Model & Parameter Definitions ---\n",
        "\n",
        "# We define a dictionary of models and their hyperparameter grids\n",
        "# Note: Parameters must be prefixed with 'classifier__' because they are inside a Pipeline\n",
        "\n",
        "MODEL_CONFIGS = {\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\"),\n",
        "        \"params\": {\n",
        "            \"classifier__n_estimators\": [100, 200, 300],\n",
        "            \"classifier__max_depth\": [None, 10, 20, 30],\n",
        "            \"classifier__min_samples_split\": [2, 5, 10],\n",
        "            \"classifier__criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "if HAS_XGB:\n",
        "    MODEL_CONFIGS[\"XGBoost\"] = {\n",
        "        \"model\": XGBClassifier(random_state=RANDOM_STATE, eval_metric='mlogloss'),\n",
        "        \"params\": {\n",
        "            \"classifier__n_estimators\": [100, 200, 300],\n",
        "            \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
        "            \"classifier__max_depth\": [3, 6, 10],\n",
        "            \"classifier__subsample\": [0.8, 1.0]\n",
        "        }\n",
        "    }\n",
        "\n",
        "# --- PART 3: Data Loading Helper ---\n",
        "\n",
        "def load_data(experiment_mode):\n",
        "    print(f\"\\n--- Loading Data for Mode: {experiment_mode} ---\")\n",
        "    if not os.path.exists(FINAL_PESV_FILE):\n",
        "        print(f\"FATAL ERROR: Could not find dataset at '{FINAL_PESV_FILE}'\")\n",
        "        return None, None\n",
        "\n",
        "    df_full = pd.read_csv(FINAL_PESV_FILE)\n",
        "\n",
        "    if experiment_mode == \"FULL\":\n",
        "        df = df_full\n",
        "    elif experiment_mode == \"VPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'VPN'].copy()\n",
        "    elif experiment_mode == \"NONVPN_ONLY\":\n",
        "        df = df_full[df_full['binary_type'] == 'NonVPN'].copy()\n",
        "    else:\n",
        "        print(f\"ERROR: Unknown mode {experiment_mode}\")\n",
        "        return None, None\n",
        "\n",
        "    if df.empty: return None, None\n",
        "\n",
        "    # Define Feature Columns\n",
        "    all_cols = set(df.columns)\n",
        "    alpha_cols = sorted([c for c in all_cols if c.startswith('alpha_pp_')])\n",
        "    delta_cols = sorted([c for c in all_cols if c.startswith(('c2s_', 's2c_', 'flow_', 'total_'))])\n",
        "    gamma_cols = sorted([c for c in all_cols if c.startswith('burst_')])\n",
        "\n",
        "    feature_sets = {\n",
        "        \"Alpha'' (\u03b1'') only\": alpha_cols,\n",
        "        \"Delta (\u03b4) only\": delta_cols,\n",
        "        \"Gamma' (\u03b3') only\": gamma_cols,\n",
        "        \"Alpha'' + Delta\": alpha_cols + delta_cols,\n",
        "        \"Alpha'' + Gamma'\": alpha_cols + gamma_cols,\n",
        "        \"Delta + Gamma'\": delta_cols + gamma_cols,\n",
        "        \"Full (\u03b1'' + \u03b4 + \u03b3')\": alpha_cols + delta_cols + gamma_cols,\n",
        "    }\n",
        "\n",
        "    return df, feature_sets\n",
        "\n",
        "# --- PART 4: Tuned Classification Task ---\n",
        "\n",
        "def run_tuned_classification(df, target_label, feature_set_name, feature_cols, model_name, config):\n",
        "    \"\"\"\n",
        "    Runs RandomizedSearchCV to find best params, then evaluates on Test set.\n",
        "    \"\"\"\n",
        "    print(f\" > Training {model_name} on {feature_set_name} ({len(feature_cols)} feats)...\")\n",
        "\n",
        "    X = df[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    y = df[target_label]\n",
        "\n",
        "    # Encode labels (Required for XGBoost)\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    class_names = [str(c) for c in le.classes_]\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_encoded, test_size=TEST_SET_SIZE, random_state=RANDOM_STATE, stratify=y_encoded\n",
        "    )\n",
        "\n",
        "    # Pipeline\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', config[\"model\"])\n",
        "    ])\n",
        "\n",
        "    # Hyperparameter Tuning (RandomizedSearchCV)\n",
        "    # We use f1_macro for scoring because of the class imbalance (Skype vs Netflix)\n",
        "    search = RandomizedSearchCV(\n",
        "        pipeline,\n",
        "        param_distributions=config[\"params\"],\n",
        "        n_iter=N_ITER_SEARCH,\n",
        "        scoring='f1_macro',\n",
        "        cv=CV_FOLDS,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    search.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    best_model = search.best_estimator_\n",
        "    best_params = search.best_params_\n",
        "\n",
        "    # Predict\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Metrics extraction\n",
        "    report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
        "\n",
        "    metrics = {\n",
        "        'model': model_name,\n",
        "        'feature_set': feature_set_name,\n",
        "        'accuracy': report['accuracy'],\n",
        "\n",
        "        # Weighted Metrics (Biased towards Skype/Majority)\n",
        "        'f1_weighted': report['weighted avg']['f1-score'],\n",
        "        'prec_weighted': report['weighted avg']['precision'],\n",
        "        'rec_weighted': report['weighted avg']['recall'],\n",
        "\n",
        "        # Macro Metrics (Treats Netflix same as Skype - Good for Imbalance)\n",
        "        'f1_macro': report['macro avg']['f1-score'],\n",
        "        'prec_macro': report['macro avg']['precision'],\n",
        "        'rec_macro': report['macro avg']['recall'],\n",
        "\n",
        "        'time': end_time - start_time,\n",
        "        'best_params': str(best_params).replace(\"classifier__\", \"\") # Clean string\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# --- PART 5: Main Loop ---\n",
        "\n",
        "def main():\n",
        "    df, feature_sets = load_data(EXPERIMENT_MODE)\n",
        "    if df is None: return\n",
        "\n",
        "    tasks = ['binary_type', 'category', 'application']\n",
        "    summary_results = {}\n",
        "\n",
        "    for task in tasks:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"--- TUNING AND EVALUATING TARGET: {task} ---\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        task_metrics = []\n",
        "\n",
        "        for model_name, config in MODEL_CONFIGS.items():\n",
        "            for fs_name, fs_cols in feature_sets.items():\n",
        "                if not fs_cols: continue\n",
        "\n",
        "                # Run Logic\n",
        "                m = run_tuned_classification(df, task, fs_name, fs_cols, model_name, config)\n",
        "                task_metrics.append(m)\n",
        "\n",
        "        summary_results[task] = task_metrics\n",
        "\n",
        "    # ... (Keep the training loops above) ...\n",
        "\n",
        "    # --- Final Reporting (REPLACED) ---\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"--- FINAL TUNED CHAMPIONSHIP RESULTS ({EXPERIMENT_MODE}) ---\")\n",
        "    print(f\"{'='*100}\\n\")\n",
        "\n",
        "    for task, results in summary_results.items():\n",
        "        print(f\"--- Target: {task} ---\")\n",
        "\n",
        "        # Sort by Macro F1\n",
        "        sorted_res = sorted(results, key=lambda x: x['f1_macro'], reverse=True)\n",
        "\n",
        "        # 1. Print the Summary Table\n",
        "        print(f\"{'Model':<15} | {'Feature Set':<22} | {'Acc':<6} | {'F1(W)':<6} | {'F1(Mac)':<8} | {'Time':<5}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for r in sorted_res:\n",
        "            print(f\"{r['model']:<15} | {r['feature_set']:<22} | \"\n",
        "                  f\"{r['accuracy']:.4f} | {r['f1_weighted']:.4f} | {r['f1_macro']:.4f}   | \"\n",
        "                  f\"{r['time']:<5.1f}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # 2. Print FULL Parameters for Top 3 Models\n",
        "        print(f\"--- \ud83c\udfc6 Top 3 Models for {task} (Full Parameters) ---\")\n",
        "        for i, r in enumerate(sorted_res[:3]):\n",
        "            print(f\"{i+1}. {r['model']} [{r['feature_set']}]\")\n",
        "            print(f\"   Accuracy: {r['accuracy']:.4f} | Macro F1: {r['f1_macro']:.4f}\")\n",
        "            print(f\"   Best Params: {r['best_params']}\") # Prints the full string\n",
        "            print(\"-\" * 50)\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaaH-YBAdFc3",
        "outputId": "46622435-78bd-4c67-f3f9-50683fb755ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing PESV v3 Tuned Championship ---\n",
            "\n",
            "--- Loading Data for Mode: FULL ---\n",
            "\n",
            "================================================================================\n",
            "--- TUNING AND EVALUATING TARGET: binary_type ---\n",
            "================================================================================\n",
            " > Training Random Forest on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training Random Forest on Delta (\u03b4) only (40 feats)...\n",
            " > Training Random Forest on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training Random Forest on Alpha'' + Delta (168 feats)...\n",
            " > Training Random Forest on Alpha'' + Gamma' (164 feats)...\n",
            " > Training Random Forest on Delta + Gamma' (76 feats)...\n",
            " > Training Random Forest on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            " > Training XGBoost on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training XGBoost on Delta (\u03b4) only (40 feats)...\n",
            " > Training XGBoost on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training XGBoost on Alpha'' + Delta (168 feats)...\n",
            " > Training XGBoost on Alpha'' + Gamma' (164 feats)...\n",
            " > Training XGBoost on Delta + Gamma' (76 feats)...\n",
            " > Training XGBoost on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            "\n",
            "================================================================================\n",
            "--- TUNING AND EVALUATING TARGET: category ---\n",
            "================================================================================\n",
            " > Training Random Forest on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training Random Forest on Delta (\u03b4) only (40 feats)...\n",
            " > Training Random Forest on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training Random Forest on Alpha'' + Delta (168 feats)...\n",
            " > Training Random Forest on Alpha'' + Gamma' (164 feats)...\n",
            " > Training Random Forest on Delta + Gamma' (76 feats)...\n",
            " > Training Random Forest on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            " > Training XGBoost on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training XGBoost on Delta (\u03b4) only (40 feats)...\n",
            " > Training XGBoost on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training XGBoost on Alpha'' + Delta (168 feats)...\n",
            " > Training XGBoost on Alpha'' + Gamma' (164 feats)...\n",
            " > Training XGBoost on Delta + Gamma' (76 feats)...\n",
            " > Training XGBoost on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            "\n",
            "================================================================================\n",
            "--- TUNING AND EVALUATING TARGET: application ---\n",
            "================================================================================\n",
            " > Training Random Forest on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training Random Forest on Delta (\u03b4) only (40 feats)...\n",
            " > Training Random Forest on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training Random Forest on Alpha'' + Delta (168 feats)...\n",
            " > Training Random Forest on Alpha'' + Gamma' (164 feats)...\n",
            " > Training Random Forest on Delta + Gamma' (76 feats)...\n",
            " > Training Random Forest on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            " > Training XGBoost on Alpha'' (\u03b1'') only (128 feats)...\n",
            " > Training XGBoost on Delta (\u03b4) only (40 feats)...\n",
            " > Training XGBoost on Gamma' (\u03b3') only (36 feats)...\n",
            " > Training XGBoost on Alpha'' + Delta (168 feats)...\n",
            " > Training XGBoost on Alpha'' + Gamma' (164 feats)...\n",
            " > Training XGBoost on Delta + Gamma' (76 feats)...\n",
            " > Training XGBoost on Full (\u03b1'' + \u03b4 + \u03b3') (204 feats)...\n",
            "\n",
            "====================================================================================================\n",
            "--- FINAL TUNED CHAMPIONSHIP RESULTS (FULL) ---\n",
            "====================================================================================================\n",
            "\n",
            "--- Target: binary_type ---\n",
            "Model           | Feature Set            | Acc    | F1(W)  | F1(Mac)  | Time \n",
            "--------------------------------------------------------------------------------\n",
            "Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.9728 | 0.9729 | 0.9579   | 110.2\n",
            "XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.9717 | 0.9718 | 0.9558   | 128.5\n",
            "XGBoost         | Delta (\u03b4) only         | 0.9717 | 0.9717 | 0.9556   | 31.9 \n",
            "Random Forest   | Delta + Gamma'         | 0.9707 | 0.9706 | 0.9539   | 76.4 \n",
            "XGBoost         | Delta + Gamma'         | 0.9707 | 0.9706 | 0.9537   | 60.0 \n",
            "XGBoost         | Alpha'' + Delta        | 0.9696 | 0.9697 | 0.9526   | 94.4 \n",
            "Random Forest   | Delta (\u03b4) only         | 0.9686 | 0.9686 | 0.9509   | 60.6 \n",
            "Random Forest   | Alpha'' + Gamma'       | 0.9675 | 0.9676 | 0.9493   | 88.8 \n",
            "XGBoost         | Alpha'' + Gamma'       | 0.9649 | 0.9649 | 0.9449   | 104.8\n",
            "Random Forest   | Alpha'' + Delta        | 0.9633 | 0.9636 | 0.9433   | 88.5 \n",
            "XGBoost         | Gamma' (\u03b3') only       | 0.9607 | 0.9606 | 0.9380   | 36.5 \n",
            "Random Forest   | Gamma' (\u03b3') only       | 0.9534 | 0.9537 | 0.9280   | 68.8 \n",
            "Random Forest   | Alpha'' (\u03b1'') only     | 0.9434 | 0.9449 | 0.9160   | 79.4 \n",
            "XGBoost         | Alpha'' (\u03b1'') only     | 0.9371 | 0.9372 | 0.9016   | 76.6 \n",
            "\n",
            "\n",
            "--- \ud83c\udfc6 Top 3 Models for binary_type (Full Parameters) ---\n",
            "1. Random Forest [Full (\u03b1'' + \u03b4 + \u03b3')]\n",
            "   Accuracy: 0.9728 | Macro F1: 0.9579\n",
            "   Best Params: {'n_estimators': 300, 'min_samples_split': 10, 'max_depth': 20, 'criterion': 'entropy'}\n",
            "--------------------------------------------------\n",
            "2. XGBoost [Full (\u03b1'' + \u03b4 + \u03b3')]\n",
            "   Accuracy: 0.9717 | Macro F1: 0.9558\n",
            "   Best Params: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1}\n",
            "--------------------------------------------------\n",
            "3. XGBoost [Delta (\u03b4) only]\n",
            "   Accuracy: 0.9717 | Macro F1: 0.9556\n",
            "   Best Params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.2}\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "--- Target: category ---\n",
            "Model           | Feature Set            | Acc    | F1(W)  | F1(Mac)  | Time \n",
            "--------------------------------------------------------------------------------\n",
            "XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.8188 | 0.7987 | 0.8329   | 656.2\n",
            "XGBoost         | Alpha'' + Delta        | 0.8172 | 0.7973 | 0.8307   | 530.9\n",
            "XGBoost         | Alpha'' + Gamma'       | 0.8151 | 0.7944 | 0.8297   | 505.6\n",
            "Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.8156 | 0.7953 | 0.8189   | 128.4\n",
            "Random Forest   | Alpha'' + Gamma'       | 0.8114 | 0.7910 | 0.8159   | 104.3\n",
            "Random Forest   | Alpha'' + Delta        | 0.8109 | 0.7912 | 0.8145   | 104.7\n",
            "Random Forest   | Alpha'' (\u03b1'') only     | 0.7748 | 0.7529 | 0.7949   | 86.7 \n",
            "XGBoost         | Alpha'' (\u03b1'') only     | 0.7700 | 0.7486 | 0.7939   | 367.9\n",
            "XGBoost         | Delta (\u03b4) only         | 0.7653 | 0.7520 | 0.7898   | 207.3\n",
            "XGBoost         | Delta + Gamma'         | 0.7632 | 0.7492 | 0.7888   | 372.7\n",
            "Random Forest   | Delta + Gamma'         | 0.7617 | 0.7478 | 0.7814   | 98.6 \n",
            "Random Forest   | Delta (\u03b4) only         | 0.7596 | 0.7462 | 0.7709   | 75.6 \n",
            "XGBoost         | Gamma' (\u03b3') only       | 0.7465 | 0.7316 | 0.7633   | 193.3\n",
            "Random Forest   | Gamma' (\u03b3') only       | 0.7376 | 0.7217 | 0.7481   | 83.2 \n",
            "\n",
            "\n",
            "--- \ud83c\udfc6 Top 3 Models for category (Full Parameters) ---\n",
            "1. XGBoost [Full (\u03b1'' + \u03b4 + \u03b3')]\n",
            "   Accuracy: 0.8188 | Macro F1: 0.8329\n",
            "   Best Params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.2}\n",
            "--------------------------------------------------\n",
            "2. XGBoost [Alpha'' + Delta]\n",
            "   Accuracy: 0.8172 | Macro F1: 0.8307\n",
            "   Best Params: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1}\n",
            "--------------------------------------------------\n",
            "3. XGBoost [Alpha'' + Gamma']\n",
            "   Accuracy: 0.8151 | Macro F1: 0.8297\n",
            "   Best Params: {'subsample': 0.8, 'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.2}\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "--- Target: application ---\n",
            "Model           | Feature Set            | Acc    | F1(W)  | F1(Mac)  | Time \n",
            "--------------------------------------------------------------------------------\n",
            "Random Forest   | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.7658 | 0.7731 | 0.8608   | 119.5\n",
            "Random Forest   | Alpha'' + Gamma'       | 0.7658 | 0.7736 | 0.8600   | 98.7 \n",
            "XGBoost         | Alpha'' + Delta        | 0.8408 | 0.8076 | 0.8594   | 387.2\n",
            "XGBoost         | Full (\u03b1'' + \u03b4 + \u03b3')    | 0.8439 | 0.8104 | 0.8594   | 487.8\n",
            "Random Forest   | Alpha'' + Delta        | 0.7622 | 0.7696 | 0.8551   | 100.8\n",
            "XGBoost         | Alpha'' + Gamma'       | 0.8408 | 0.8069 | 0.8550   | 374.3\n",
            "Random Forest   | Alpha'' (\u03b1'') only     | 0.7470 | 0.7521 | 0.8498   | 82.1 \n",
            "XGBoost         | Alpha'' (\u03b1'') only     | 0.8193 | 0.7840 | 0.8299   | 274.2\n",
            "XGBoost         | Delta (\u03b4) only         | 0.7837 | 0.7534 | 0.8019   | 166.9\n",
            "XGBoost         | Delta + Gamma'         | 0.7816 | 0.7497 | 0.7995   | 295.0\n",
            "XGBoost         | Gamma' (\u03b3') only       | 0.7617 | 0.7290 | 0.7761   | 168.7\n",
            "Random Forest   | Delta + Gamma'         | 0.6857 | 0.6949 | 0.7707   | 94.2 \n",
            "Random Forest   | Delta (\u03b4) only         | 0.6894 | 0.6986 | 0.7695   | 72.7 \n",
            "Random Forest   | Gamma' (\u03b3') only       | 0.6674 | 0.6755 | 0.7477   | 80.3 \n",
            "\n",
            "\n",
            "--- \ud83c\udfc6 Top 3 Models for application (Full Parameters) ---\n",
            "1. Random Forest [Full (\u03b1'' + \u03b4 + \u03b3')]\n",
            "   Accuracy: 0.7658 | Macro F1: 0.8608\n",
            "   Best Params: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': None, 'criterion': 'gini'}\n",
            "--------------------------------------------------\n",
            "2. Random Forest [Alpha'' + Gamma']\n",
            "   Accuracy: 0.7658 | Macro F1: 0.8600\n",
            "   Best Params: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 20, 'criterion': 'entropy'}\n",
            "--------------------------------------------------\n",
            "3. XGBoost [Alpha'' + Delta]\n",
            "   Accuracy: 0.8408 | Macro F1: 0.8594\n",
            "   Best Params: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.2}\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}