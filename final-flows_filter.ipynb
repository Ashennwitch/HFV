{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4811,
     "status": "ok",
     "timestamp": 1761992619169,
     "user": {
      "displayName": "Hanif Nur Ilham Sanjaya",
      "userId": "10100194631026074709"
     },
     "user_tz": -420
    },
    "id": "O_G6IPR23GEq",
    "outputId": "1bf8aa18-e1d6-4675-c166-aad97da783b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scapy in /usr/local/lib/python3.12/dist-packages (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ0DR5Zf5q7z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "# --- Scapy Imports ---\n",
    "# Import only the most basic and stable layers\n",
    "from scapy.all import rdpcap, TCP, UDP, IP\n",
    "from scapy.layers.dns import DNS\n",
    "from scapy.layers.dhcp import DHCP, BOOTP\n",
    "from scapy.layers.ntp import NTP\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Directory containing the split pcap files from Step 2 (~309k flows)\n",
    "INPUT_DIR = '/content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/flow_yg_blm'\n",
    "\n",
    "# Directory where the final cleaned pcap files will be saved (~8.7k flows)\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/1 Skripsi/Dataset/ISCX-VPN-NonVPN-2016/clean_flow_yg_blm\"\n",
    "\n",
    "# --- Rule A: Protocol Filtering ---\n",
    "# DISALLOWED_PROTOCOLS: Check for protocols that Scapy can easily identify as layers.\n",
    "DISALLOWED_PROTOCOLS = {\n",
    "    DNS,\n",
    "    NTP,\n",
    "    DHCP,\n",
    "    BOOTP\n",
    "}\n",
    "# DISALLOWED_UDP_PORTS: A more robust way to block protocols based on their standard ports.\n",
    "DISALLOWED_UDP_PORTS = {\n",
    "    137,   # NBNS (NetBIOS Name Service)\n",
    "    1900,  # SSDP\n",
    "    5353,  # MDNS\n",
    "    5355   # LLMNR\n",
    "}\n",
    "\n",
    "# --- Logging Setup ---\n",
    "logging.basicConfig(\n",
    "    filename='filtering_log_final.txt',\n",
    "    level=logging.INFO,\n",
    "    filemode='w',  # Overwrite the log file on each run\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "\n",
    "def is_flow_valid_final(pcap_file_path):\n",
    "    \"\"\"\n",
    "    Analyzes a single flow pcap file and applies ALL filtering rules (A, B, and C)\n",
    "    to determine if it belongs in the final dataset.\n",
    "    Returns a tuple: (is_valid, reason_for_invalidation)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        packets = rdpcap(pcap_file_path)\n",
    "    except Exception as e:\n",
    "        return False, f\"Scapy could not read file. Error: {e}\"\n",
    "\n",
    "    if not packets:\n",
    "        return False, \"File is empty or corrupt\"\n",
    "\n",
    "    # --- Implement ALL Filtering Rules ---\n",
    "    first_packet = packets[0]\n",
    "\n",
    "    # Rule B: TCP 3-Way Handshake Check (applies only to TCP flows)\n",
    "    if TCP in first_packet:\n",
    "        if len(packets) > 4 and 'S' not in first_packet[TCP].flags:\n",
    "            return False, \"Rule B Failed: Invalid TCP handshake start\"\n",
    "\n",
    "    # Loop through all packets to check Rules A and C\n",
    "    for pkt in packets:\n",
    "        # Rule A (Part 1): Check for disallowed application-layer protocols by Scapy layer\n",
    "        for protocol_layer in DISALLOWED_PROTOCOLS:\n",
    "            if protocol_layer in pkt:\n",
    "                return False, f\"Rule A Failed: Disallowed protocol ({protocol_layer.name})\"\n",
    "\n",
    "        if UDP in pkt:\n",
    "            # Rule A (Part 2): Check for disallowed UDP protocols by their well-known port numbers\n",
    "            if pkt[UDP].sport in DISALLOWED_UDP_PORTS or pkt[UDP].dport in DISALLOWED_UDP_PORTS:\n",
    "                return False, f\"Rule A Failed: Disallowed UDP port used\"\n",
    "\n",
    "            # Rule C: UDP Beacon Check\n",
    "            # Check for broadcast UDP packets containing \"Beacon~\" in the payload\n",
    "            if IP in pkt and pkt[IP].dst == '255.255.255.255':\n",
    "                try:\n",
    "                    payload = bytes(pkt[UDP].payload)\n",
    "                    if b'Beacon~' in payload:\n",
    "                        return False, \"Rule C Failed: UDP Beacon flow detected\"\n",
    "                except Exception:\n",
    "                    # Payload might be empty or malformed, safe to ignore and continue\n",
    "                    pass\n",
    "\n",
    "    # If the flow has passed all the checks, it's valid\n",
    "    return True, \"Valid\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to iterate through all flow files and filter them to the final dataset.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Combined Filtering (to get ~8,763 flows) ---\")\n",
    "\n",
    "    if not os.path.isdir(INPUT_DIR):\n",
    "        print(f\"[FATAL ERROR] Input directory '{INPUT_DIR}' not found.\")\n",
    "        print(\"Please make sure you have run Step 2 successfully.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    print(f\"Final cleaned flows will be saved in: '{OUTPUT_DIR}'\")\n",
    "    print(f\"A detailed log will be saved to: 'filtering_log_final.txt'\")\n",
    "    print(\"\\nThis process will take a very long time. Please be patient.\\n\")\n",
    "\n",
    "    total_flows = 0\n",
    "    kept_flows = 0\n",
    "    discarded_flows = 0\n",
    "\n",
    "    # Walk through the nested directory structure of split_flows\n",
    "    for root, _, files in os.walk(INPUT_DIR):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.pcap'):\n",
    "                total_flows += 1\n",
    "                pcap_path = os.path.join(root, filename)\n",
    "\n",
    "                is_valid, reason = is_flow_valid_final(pcap_path)\n",
    "\n",
    "                if is_valid:\n",
    "                    kept_flows += 1\n",
    "                    try:\n",
    "                        shutil.copy(pcap_path, OUTPUT_DIR)\n",
    "                    except Exception as e:\n",
    "                        log_msg = f\"ERROR COPYING: {pcap_path} | Error: {e}\"\n",
    "                        print(log_msg)\n",
    "                        logging.error(log_msg)\n",
    "                else:\n",
    "                    discarded_flows += 1\n",
    "                    logging.info(f\"DISCARDED: {pcap_path} | Reason: {reason}\")\n",
    "\n",
    "                # Print a progress update every 1000 files processed\n",
    "                if total_flows % 1000 == 0:\n",
    "                    print(f\"Processed: {total_flows} | Kept: {kept_flows} | Discarded: {discarded_flows}\")\n",
    "\n",
    "    print(\"\\n--- Final Filtering Complete ---\")\n",
    "    print(f\"Total flows processed: {total_flows}\")\n",
    "    print(f\"Total flows kept: {kept_flows}\")\n",
    "    print(f\"Total flows discarded: {discarded_flows}\")\n",
    "    print(f\"\\nYour final, cleaned dataset is now available in the '{OUTPUT_DIR}' directory.\")\n",
    "    print(f\"The final count should be near the target of 8,763.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPEc1wr7QiEAxlyeKw6cxdL",
   "machine_shape": "hm",
   "mount_file_id": "16RtyS-V7Lt3zyE473EsI8ZUC97nXhhWy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
